{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ILEE 3D mode (V 1.0).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TuRFU2eg-_tKnARY2GL9y4W5DITrF7Wh",
      "authorship_tag": "ABX9TyPkBfAaf4TJxSe6lXxbdZ0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phylars/ILEE_CSK/blob/ipynb/ILEE_3D_mode_(V_1_0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7Tj2_7i686D"
      },
      "source": [
        "# **Preparation**\n",
        "\n",
        "Please transfer you confocal format files to raw (stack) tiff images using ImageJ/FIJI, and put them in a new folder. \n",
        "*   If you wish to run the pipeline in Google Colab, please upload the tiff folder to your Google Drive; \n",
        "*   If you wish to run the pipeline locally, please download this .ipynb file to your local device and open it by Jupyter Notebook. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsKrDTbZsHXj",
        "cellView": "form"
      },
      "source": [
        "#@title Install ILEE_CSK and dependencies\n",
        "!pip -q install -U ILEE_CSK \n",
        "import ILEE_CSK \n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "print('Installation completes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_R9cQS_Us_vi"
      },
      "source": [
        "#@title Inspect the data structure of your tif image\n",
        "#@markdown All your image samples should be taken under the same confocal setting. Please input the file path of any one of your image file in this batch of experiment, below. It can be local (for jupyter notebook) or in your Google Drive (Google Colab):\n",
        "\n",
        "example_tif_file_path = \"(input your example tiff file path here)\"  #@param {type: \"string\"}\n",
        "img_example = io.imread(example_tif_file_path)\n",
        "print('The image array structure is', img_example.shape)\n",
        "\n",
        "#@markdown (Optional/Recommended): This pipeline also provide data visualization and significance analysis. To enable this, please name your tiff files as (group_name)-(repeat_index).tif, such as mock-1.tif, mock-2.tif, or treatment1-1.tif ... The hyphen '-' must occur only once. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRmm6srlFxDX"
      },
      "source": [
        "The image array structure needs to meet 2 requirements:\n",
        "\n",
        "*   Your image array structure should be 3D or 4D (seeing 3 or 4 numbers in the tuple). If it is 2D, you may be using a projected image, ILEE_CSK fully supports it but it cannot be processed in this pipeline. If it has 5 or more dimension, this is an abnormal data structure and please submit a bug report in the Github.\n",
        "*   If it is 4D, the dimension with lowest size should be your channel, and the the dimension with second lowest size should be your z-axis.\n",
        "\n",
        "To learn which channel is your objective, please run the following step to inspect your example image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Fea04aCaFwH6"
      },
      "source": [
        "#@title Inspect the channels of the example image\n",
        "def align_image_dimension(img):\n",
        "    img_size = np.array(img.shape)\n",
        "    dimension = img_size.shape[0]\n",
        "    df_dimension = pd.DataFrame(data = img_size, columns = ['dimension_size'])\n",
        "    df_dimension['dimension_index'] = range(img_size.shape[0])\n",
        "    df_dimension = df_dimension.sort_values(by = ['dimension_size', 'dimension_index'])\n",
        "    if (dimension <= 2):\n",
        "      print ('Error: image have less than 3 dimensions; please check data structure')\n",
        "      return()\n",
        "    elif (dimension == 3):\n",
        "      result = np.moveaxis(img, source = np.array(df_dimension['dimension_index']), destination = np.array([0,1,2]))\n",
        "    elif (dimension == 4):\n",
        "      result = np.moveaxis(img, source = np.array(df_dimension['dimension_index']), destination = np.array([0,1,2,3]))\n",
        "    else:\n",
        "      print('image has more than 4 dimension (x, y, z, and channel); please check data structure')\n",
        "      return()\n",
        "    return (result)\n",
        "\n",
        "if(len(img_example.shape) == 3):\n",
        "  print('Your image sample is a 3D array (does not have channel dimension). Please set objective_channel to None in the next step.')\n",
        "  print('\\n')\n",
        "  img_example = align_image_dimension(img_example)\n",
        "  img_example_p = np.amax(img_example, axis=0)\n",
        "  print('Below is a z-axis projected of your image sample:')\n",
        "  plt.figure(figsize = (6, 6))\n",
        "  plt.imshow(img_example_p)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "elif(len(img_example.shape) == 4):\n",
        "  print('Your image sample is a 4D array (contains channel dimension). The projection image of each channel is shown below:')\n",
        "  print('\\n')\n",
        "  img_example = align_image_dimension(img_example)\n",
        "  for i in range(img_example.shape[0]):\n",
        "    img_example_p = np.amax(img_example[i,:,:,:], axis=0)\n",
        "    print('channel', i)\n",
        "    plt.figure(figsize = (6, 6))\n",
        "    plt.imshow(img_example_p)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print('\\n')\n",
        "print('Please set the objective_channel to the correct channel index for cytoskeleton in the next step.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dpkimxja0Kvq"
      },
      "source": [
        "#@title Input the image folder containing all the raw tiffs in this experiment\n",
        "\n",
        "folder_path = '(input your tiff folder path here)'  #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "e0HjhAZovxyI"
      },
      "source": [
        "#@title Estimate optimal K1 and K2\n",
        "#@markdown K2 is an parameter required for ILEE processing. We recommend use the optimal K2 calculated by this function for most of the cases.\n",
        "\n",
        "#@markdown According to the projected images of each channel, shown above, please input channel index of cytoskeleton fluorescence:\n",
        "\n",
        "objective_channel_index =   (input your channel index of cytoskeleton learned above)#@param {type: \"number\"}\n",
        "optimal_K2 = ILEE_CSK.opt_k2(folder_path, target_channel = objective_channel_index)\n",
        "optimal_K1 = 10**((np.log10(2.5) + np.log10(optimal_K2))/2)\n",
        "optimal_K1 = np.round(optimal_K1)\n",
        "optimal_K2 = np.round(optimal_K2)\n",
        "print('The estimated optimal K1 is', optimal_K1)\n",
        "print('The estimated optimal K2 is', optimal_K2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xzRnK7Z76XF"
      },
      "source": [
        "# **Start processing your samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl_6G9f72iAj",
        "cellView": "form"
      },
      "source": [
        "#@title Set input parameters and run\n",
        "#@markdown Input channel index of cytoskeleton fluorescence:\n",
        "objective_channel_index = (input your channel index of cytoskeleton learned above)  #@param {type: \"number\"}\n",
        "#@markdown Copy your optimal K1 to this place:\n",
        "K1 =   #@param {type: \"number\"}\n",
        "#@markdown Copy your optimal K2 to this place:\n",
        "K2 =  #@param {type: \"number\"}\n",
        "#@markdown Check the voxel size by μm using ImageJ/Fiji and set them here:\n",
        "xy_unit =  #@param {type: \"number\"}\n",
        "z_unit =  #@param {type: \"number\"}\n",
        "#@markdown Set the pixel size for cytoskeleton indices computation. Please either input 1 (Output pixel unit PU will be \"pixel\"), or the xy_unit above (Output pixel unit PU will be μm):\n",
        "pixel_size = 1 #@param {type:\"number\"}\n",
        "#@markdown Set whether use only K1 to process ILEE. It saves 2/3 of total time with minor sacrifice of accuracy:\n",
        "single_k1 = True #@param {type:\"boolean\"}\n",
        "#@markdown Set whether to oversample the image for bundling analysis. Greatly increase accuracy but consume extra 2-5 min.\n",
        "oversampling_for_bundle = False #@param {type:\"boolean\"}\n",
        "\n",
        "df_result = ILEE_CSK.analyze_document_3D (folder_path = folder_path,\n",
        "                                          obj_channel = objective_channel_index,\n",
        "                                          k1 = K1,\n",
        "                                          k2 = K2,\n",
        "                                          xy_unit = xy_unit,\n",
        "                                          z_unit = z_unit,\n",
        "                                          pixel_size = pixel_size, \n",
        "                                          single_k1 = single_k1,\n",
        "                                          oversampling_for_bundle = oversampling_for_bundle,\n",
        "                                          use_GPU = False)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5AJwQdvS3Cb",
        "cellView": "form"
      },
      "source": [
        "#@title Show your data table\n",
        "df_result.style"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ePOBpTCGq946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "78bd6fe5-c2ad-4cb4-e723-8df4c451bc02"
      },
      "source": [
        "#@title Download the data as Excel file.\n",
        "from google.colab import files\n",
        "df_result.to_excel('result.xlsx')\n",
        "files.download('result.xlsx')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_42f4f8e5-906a-457a-8306-dd822bc40150\", \"result.xlsx\", 6445)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v3cRHqU9pLH",
        "cellView": "form"
      },
      "source": [
        "#@title Visualize your data\n",
        "\n",
        "#@markdown As noted above, to enable visualization and significance test, your tiff files must be named as \"xxx(group)-xxx(index)\".\n",
        "ILEE_CSK.visualize_results(df_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB0NY7VScpf3",
        "cellView": "form"
      },
      "source": [
        "#@title Significant test\n",
        "\n",
        "p_thres = 0.05  #@param {type: \"number\"}\n",
        "\n",
        "Data_property = \"I am measuring biological samples and/or want to learn the biological features at my experiment condition. (Use post-hoc, Holm\\u2013Bonferroni method)\"  #@param ['I am measuring biological samples and/or want to learn the biological features at my experiment condition. (Use post-hoc, Holm–Bonferroni method)', 'I am measuring biological samples and/or want to learn the biological features at my experiment condition. (Use post-hoc, FDR Benjamini–Hochberg method)', 'I am not using data to interpret biological features and the image per-se is ground truth. (No post-hoc)']\n",
        "if (Data_property == 'I am measuring biological samples and/or want to learn the biological features at my experiment condition. (Use post-hoc, Holm–Bonferroni method)'):\n",
        "  p_adjust = 'holm'\n",
        "elif (Data_property == 'I am measuring biological samples and/or want to learn the biological features at my experiment condition. (Use post-hoc, FDR Benjamini–Hochberg method)'):\n",
        "  p_adjust = 'fdr_bh'\n",
        "else:\n",
        "  p_adjust = None\n",
        "#@markdown Recommend Holm-Bonferroni method for post-hoc. In some rare cases, Holm-Bonferroni may have very abnormal results; try FDR Benjamini–Hochberg method instead then.\n",
        "\n",
        "print('Testing with P value threshold at', p_thres)\n",
        "print('Family-wise error correction :', p_adjust)\n",
        "print('\\n')\n",
        "\n",
        "sd_table = ILEE_CSK.total_df_multiple_comparison (df = df_result, cat_var_column = 'group', p_thres = p_thres, column_types = ['float'], p_adjust = p_adjust)\n",
        "sd_table.style"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}